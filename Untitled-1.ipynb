{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Found: ['CHESSA BACHA.jpg', 'laddi.jpg', 'MUHAMMAD AZHAR(TRANSPORT MAMANGER).jpg', 'MUHAMMAD IMRAN(MANAGER).jpg', 'MUHAMMAD NOMAN (AI).jpg', 'MUhammad Noman.jpg', 'MUHAMMAD REHMAN (AGRICULTURE OFFICER ).jpg', 'SHAHAD LOND.jpg']\n",
      "Class Names: ['CHESSA BACHA', 'laddi', 'MUHAMMAD AZHAR(TRANSPORT MAMANGER)', 'MUHAMMAD IMRAN(MANAGER)', 'MUHAMMAD NOMAN (AI)', 'MUhammad Noman', 'MUHAMMAD REHMAN (AGRICULTURE OFFICER )', 'SHAHAD LOND']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Path to the images folder\n",
    "path = 'Attendance'\n",
    "os.makedirs(path, exist_ok=True)  # Ensure the folder exists\n",
    "images = []\n",
    "classNames = []\n",
    "myList = os.listdir(path)\n",
    "print(\"Images Found:\", myList)\n",
    "\n",
    "# Load images and class names\n",
    "for cl in myList:\n",
    "    curImg = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(cv2.cvtColor(curImg, cv2.COLOR_BGR2GRAY))  # Convert to grayscale\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "print(\"Class Names:\", classNames)\n",
    "\n",
    "# Initialize the Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Attendance tracking\n",
    "attendance_marked = set()\n",
    "\n",
    "def markAttendance(name):\n",
    "    if name not in attendance_marked:\n",
    "        attendance_marked.add(name)\n",
    "        with open('AttendanceWrite.txt', 'a') as f:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'{name},{dtString}\\n')\n",
    "\n",
    "def preprocessFace(face):\n",
    "    \"\"\"Preprocess the detected face for better matching.\"\"\"\n",
    "    face = cv2.resize(face, (100, 100))  # Resize to uniform size\n",
    "    face = cv2.equalizeHist(face)  # Equalize histogram for better contrast\n",
    "    return face\n",
    "\n",
    "def matchFace(faceCrop, images, classNames):\n",
    "    \"\"\"Match the detected face with the dataset.\"\"\"\n",
    "    bestMatch = None\n",
    "    minError = float('inf')  # Initialize with a high value\n",
    "    for idx, img in enumerate(images):\n",
    "        imgResized = cv2.resize(img, (faceCrop.shape[1], faceCrop.shape[0]))\n",
    "        error = np.sum((faceCrop - imgResized) ** 2)  # Sum of squared differences\n",
    "        if error < minError:\n",
    "            minError = error\n",
    "            bestMatch = classNames[idx]\n",
    "    return bestMatch if minError < 1e6 else \"Unknown\"  # Use a threshold for unknown faces\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_skip = 5  # Process every 5th frame\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture frame from camera.\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray, \n",
    "        scaleFactor=1.1, \n",
    "        minNeighbors=5,  # Higher value reduces false positives\n",
    "        minSize=(50, 50)  # Ignore very small faces\n",
    "    )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        faceCrop = gray[y:y + h, x:x + w]\n",
    "        faceCrop = preprocessFace(faceCrop)  # Preprocess the cropped face\n",
    "        name = matchFace(faceCrop, images, classNames)\n",
    "\n",
    "        # Display the results on the frame\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(img, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "        if name != \"Unknown\":\n",
    "            markAttendance(name)\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):  # Press 'q' to exit\n",
    "        break\n",
    "    elif key == ord('p'):  # Press 'p' to take a photograph\n",
    "        for (x, y, w, h) in faces:\n",
    "            faceCrop = gray[y:y + h, x:x + w]\n",
    "            faceCrop = preprocessFace(faceCrop)\n",
    "            new_name = input(\"Enter the name for the new person: \")\n",
    "            cv2.imwrite(f'{path}/{new_name}.jpg', faceCrop)\n",
    "            images.append(faceCrop)\n",
    "            classNames.append(new_name)\n",
    "            print(f\"New person saved as {new_name}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
